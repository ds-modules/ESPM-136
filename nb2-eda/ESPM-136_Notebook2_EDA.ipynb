{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00001-eedf9a46-cb0c-42bc-a90f-96265663c0d3",
    "deepnote_cell_type": "markdown",
    "tags": [
     "ignore"
    ]
   },
   "source": [
    "## [ESPM-136] Notebook 2: Company Emissions Exploratory Data Analysis (EDA)\n",
    "\n",
    "Welcome to the second Jupyter Notebook for ESPM 136! In the previous notebook, you went through a small introduction to coding and performing data analysis in Python and Jupyter Notebooks. In this notebook, we'll be going through a **more applicable data analysis and visualization process of real-world data**, created straight from the company emissions Google Form you filled out before!\n",
    "\n",
    "The process of looking at, summarizing, analyzing, and visualizing data that we'll be going through today is commonly referred to as **exploratory data analysis**. As we go through the notebook, hopefully you'll understand just how useful it can be for gaining a better understanding of trends in data we're interested in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feeling stuck or want extra help with this notebook? Contact Data Peer Consultants!\n",
    "\n",
    "If you find yourself having trouble with any content in this notebook, **Data Peer Consultants** are an excellent resource! Click [here](https://dlab.berkeley.edu/training/frontdesk-info) to locate live help.\n",
    "Peer Consultants are there to answer all data-related questions, whether it be about the content of this notebook, applications of data science in the world, or other data science courses offered at Berkeley."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: 2px solid #003262\">\n",
    "<hr style=\"border: 2px solid #C9B676\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Outcomes\n",
    "\n",
    "Working through this notebook, you will learn about:\n",
    "1. Basic table functions for **viewing and conditionally selecting data**\n",
    "2. More advanced table functions for **performing detailed data analysis**\n",
    "3. **Creating visualizations** to better understand our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: 2px solid #003262\">\n",
    "<hr style=\"border: 2px solid #C9B676\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00003-a9cd1167-2276-4e0f-85b6-43d803731627",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Recap of What We've Done So Far\n",
    "\n",
    "In Assignment #1 you **gathered carbon emissions data and evaluated internal decarbonization strategies for two companies of your choice** and submitted all of this information into a Google Form. We will now be **using Jupyter Notebooks to analyze the data** that you collected!\n",
    "\n",
    "As you learned in the first notebook, we use Jupyter Notebooks because this interactive environment allows us to work with code, text, and visualizations all at once. This is important especially in the context of corporate decarbonization because we want to learn how to manipulate the data you collected, as well as understand the meaning behind the manipulations to **understand how a company's carbon reporting compares with the actual internal actions they are taking to decarbonize.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: 2px solid #003262\">\n",
    "<hr style=\"border: 2px solid #C9B676\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00003-058e2913-9587-45ac-8c2f-f284333ac4f3",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Importing Modules and Taking an Initial Look at the Data\n",
    "\n",
    "As stated previously, in this notebook we'll be utilizing data exported from the Google Form that you filled out based on company emissions. From the Google Form, we were able to export the results as a CSV (comma-separated value) file. We cleaned up and anonymized the data, and we uploaded it to the same folder that this notebook is located in. Thanks to this pre-processing, we can now load in our data to a table object from the `datascience` module!\n",
    "\n",
    "As with the first notebook, we need to import the modules necessary for this notebook. You can do this by running (clicking the cell and hitting `Cmd/Ctrl`+`Enter`, or clicking the cell and hitting the `Run` button at the top) the following code cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to import the modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datascience import *\n",
    "from ipywidgets import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "import seaborn as sns, plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all the modules we need, we can load our original CSV file into a table object from the `datascience` module!\n",
    "\n",
    "The `.show()` command in the cell below allows us to see a specified number of rows of the table. In this case, we want to see the first five rows of the table to see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to create our emissions table object\n",
    "emissions = Table.read_table('emissions.csv')\n",
    "emissions.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Dictionary\n",
    "\n",
    "Now that we've taken an intial glance at the data that you collected, let's familiarize ourselves with the contents of the `emissions` table. The **data dictionary** below reveals information about each column in the table regarding what the column represents and the type of the data in the column. Data dictionaries are useful for providing context and understanding of what the data represents for anyone working with the data.\n",
    "\n",
    "|Column Name| Meaning |Type|\n",
    "|--|--|--|\n",
    "|Company Name| The name of the company chosen to report data| category |\n",
    "|Company Sector| The industry sector the company belongs in| category |\n",
    "|Company Sector (Other)|An optional field if the company's sector was not one of the given options|category |\n",
    "|Year of CDP Disclosure|The submission year of the report. The data provided represents the previous year.|number|\n",
    "|Scope 1 value|The company's direct GHG emissions, given in metric tons of CO2e|number|\n",
    "|Scope 2 value (location-based)|The company's indirect (location-based) GHG emissions, given in metric tons of CO2e |number |\n",
    "|Scope 2 value (market-based)|The company's indirect (market-based) GHG emissions, given in metric tons of CO2e|number |\n",
    "|Scope 3 value| The company's indirect GHG emissions that come from its value chain, given in metric tons of CO2e| number |\n",
    "|Total Revenue| The company's total revenue for a given year| number |\n",
    "|Currency of Total Revenue|The currency of the company's total revenue|category|\n",
    "|Internal Price on Carbon|An indicator of if the company implements internal carbon pricing |category|\n",
    "|Price|Internal price on carbon  | number|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: 2px solid #003262\">\n",
    "<hr style=\"border: 2px solid #C9B676\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00006-dadd2623-2173-4cdb-8c95-207741ecc765",
    "deepnote_cell_type": "markdown",
    "tags": [
     "ignore"
    ]
   },
   "source": [
    "## 1. Basic Table Operations: `select`, `where`, `sort`\n",
    "\n",
    "Now that we have learned how to import our data from a CSV file, we can begin doing some interesting exploratory data analysis to see what information our data can tell us! Oftentimes, our data has a lot more information than we actually need, or it may not be in the correct order. To obtain the data we want, we can use utilize basic table methods such as `select`, `where`, and `sort` to filter out columns, rows, and sort our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Selecting Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes when doing data analysis, we only want to look at a subset of columns. Having too many columns can make the table hard to read if we are only interested in certain information. **We can pick which columns we want to see using the table method `.select()`.**\n",
    "\n",
    "When we call this method, we specify which columns we want, and it returns a brand new table with only the specified columns in the order they are inputted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, if we wanted to select only the companies and their sector we can run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions.select('Company Name', 'Company Sector')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Conditioning on Rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now know how to select certain columns of interest, but what if we wanted to only see rows in which the data meets a certain condition? The `.where()` method allows us to do exactly this. \n",
    "\n",
    "This method takes in two arguments:\n",
    "   1. The **name of the column** whose values must meet a certain condition\n",
    "   2. The predicate function that states **the condition the row must meet**\n",
    "   \n",
    "For example, if we wanted to only select the rows where the company is H&M, we could do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions.where('Company Name', are.equal_to('H&M'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell above outputs a copy of the original table but **only includes rows where the company is H&M**. There are many other predicate functions -- here are a few common ones you may find useful in the next notebook: \n",
    "\n",
    "|Predicate|Example|Result|\n",
    "|-|-|-|\n",
    "|`are.equal_to`|`are.equal_to(50)`|Find rows with values equal to 50|\n",
    "|`are.not_equal_to`|`are.not_equal_to(50)`|Find rows with values not equal to 50|\n",
    "|`are.above`|`are.above(50)`|Find rows with values above (and not equal to) 50|\n",
    "|`are.above_or_equal_to`|`are.above_or_equal_to(50)`|Find rows with values above 50 or equal to 50|\n",
    "|`are.below`|`are.below(50)`|Find rows with values below 50|\n",
    "|`are.between`|`are.between(2, 10)`|Find rows with values above or equal to 2 and below 10|\n",
    "|`are.between_or_equal_to`|`are.between_or_equal_to(2, 10)`|Find rows with values above or equal to 2 and below or equal to 10|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Sorting Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aside from selecting the desired columns and rows that we want, we can also sort the values in a certain column. The `.sort()` method accomplishes this if we pass in the column we want to sort by. By default, this method sorts a column's values in ascending order (in other words, we see the smallest values first) unless an *optional* second argument `descending = True` is passed into `.sort()`.\n",
    "\n",
    "If we wanted to sort a column that contains text, `.sort()` will sort the values alphabetically from A-Z (i.e. ascending order). For example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions.sort('Company Sector')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `emissions` data is already sorted by company name alphabetically from A-Z. However, if we wanted to sort the company names alphabetically from Z-A (i.e. descending order), we would run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions.sort('Company Name', descending = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this section, hopefully you can see how basic table operations like `select`, `where`, and `sort` can be very useful when exploring our data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: 2px solid #003262\">\n",
    "<hr style=\"border: 2px solid #C9B676\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. More Advanced Table Operations: `apply`, `group`, `pivot`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have learned how to get the data we want from the dataset and format it to our preferences, we can start exploring more advanced table techniques such as applying functions to data, grouping data based on specific criteria, and pivoting data to reshape it for advanced analysis and visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Apply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <p style=\"font-size:20px\">This section is advanced/optional\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.apply()` method applies a function to each element of a data structure and returns the result of that function call for each element. When we call this function, we need to specify **the function we are using** and **which column(s) we are applying it to**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our data, a use case of the `.apply()` method would be performing the same calculation on each element of a column. For example, we notice from the dataset that the `Currency of Total Revenue` column contains different currencies, which could make numerical comparisons on the `Total Revenue` value difficult. As a result, we would like to implement a function on the `Total Revenue` column that changes all the currency to USD.\n",
    "\n",
    "**Note:** A lot of the code in the following example is more advanced than we're expecting you to understand -- this just serves as an example of a more complex way in which we can use the `.apply()` method!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code helps us see all of the unique currencies in our dataset\n",
    "np.unique(emissions['Currency of Total Revenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, let's create a new column with both the revenue and its currency in the format of [Currency, Revenue]\n",
    "combined = [[emissions['Currency of Total Revenue'][i], emissions['Total Revenue'][i]] for i in range(len(emissions['Currency of Total Revenue']))]\n",
    "emissions['Revenue with Currency'] = combined\n",
    "emissions.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, we write our own custom function that we'll be using with `.apply()`. Essentially, the function takes in a currency measurement and then returns the revenue value multiplied by the USD conversion rate.\n",
    "\n",
    "Again, feel free to look through the code below to see how it works, but don't worry if you don't fully understand it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes in all elements in the \"Revenue with Currency\" column and turns all the non-USD revenue into USD currency\n",
    "def toUSD(i):\n",
    "    dic = {\n",
    "    'AUD': 0.75,   # 1 AUD to USD\n",
    "    'CAD': 0.78,   # 1 CAD to USD\n",
    "    'CHF': 1.09,   # 1 CHF to USD\n",
    "    'DKK': 0.15,   # 1 DKK to USD\n",
    "    'EUR': 1.16,   # 1 EUR to USD\n",
    "    'GBP': 1.37,   # 1 GBP to USD\n",
    "    'JPY': 0.009,  # 1 JPY to USD\n",
    "    'KRW': 0.0009, # 1 KRW to USD\n",
    "    'NOK': 0.11,   # 1 NOK to USD\n",
    "    'RUB': 0.014,  # 1 RUB to USD\n",
    "    'SEK': 0.11,   # 1 SEK to USD\n",
    "    'USD': 1       # No Change\n",
    "    }\n",
    "    return i[1] * dic[i[0]] # The revenue multiplied by the corresponding USD conversion rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, we'll use `.apply()` to create a new column of the function applied to the currency column in order to receive the currencies in USD!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions['Revenue (USD)'] = emissions.apply(toUSD, 'Revenue with Currency')\n",
    "emissions = emissions.drop('Revenue with Currency') # dropping this column so the dataset does not look too messy\n",
    "emissions.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's another example of using `.apply()`: we can use it to transform a numerical variable into a categorical variable. As an example, say we want to categorize the `Total Revenue` amounts into \"high\", \"medium\", or \"low\". We can achieve this using the `.apply()` function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to create the function needed for this operation\n",
    "def rev_level(revenue):\n",
    "    if revenue > 10 ** 10:\n",
    "        return 'High'\n",
    "    if revenue < 10 ** 5:\n",
    "        return 'Low'\n",
    "    else:\n",
    "        return 'Medium'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to apply the function to the dataset and add the new column\n",
    "emissions['Revenue Level'] = emissions.apply(rev_level, 'Revenue (USD)')\n",
    "emissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These examples were more advanced but applicable use cases of the `.apply()` function. It can also be used in simpler cases; as an example, if we had data in a column that needed to be multiplied or divided by a specific factor, we could easily use `.apply()` to apply the multiplication / division to every piece of data in the column!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we now have revenues with the same format, we can perform some aggregation of our data with the `.group()` function, which  groups data by a specific attribute, allowing for analysis and numeric summarization within each group. In the following example, we can use it to look at the average revenue of each company sector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, you can see the call to `.group()` in the second line, **where the first value in the parenthesis is the column name we want to group by, and the second value in the parenthesis is the function we want to use to aggregate the numeric data together** (in this case, we're calculating the average / mean revenue in USD of the data grouped by company sector)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emission_g = emissions.select('Company Sector', 'Revenue (USD)') # Select the columns we want to look at\n",
    "emission_g.group('Company Sector', np.mean) # Call the group function with the column and aggregation function we want to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, we use another aggregation function (the median) to show that there are multiple aggregation functions we can use to summarize our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could use other numeric functions besides the average, such as the median, with our grouped data\n",
    "emission_g.group('Company Sector', np.median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.group()` method also allows us to group the data by more than one variable! In the following cell, we put the `Company Name` and `Company Sector` column names in a list (denoted by the square brackets) and then group by those values. From there, we calculate the maximum value of the revenue in USD among these groupings!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also group the data by more than one variable\n",
    "emission_g1 = emissions.select('Company Sector', 'Company Name', 'Revenue (USD)')\n",
    "emission_g1.group(['Company Sector', 'Company Name'], np.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <p style=\"font-size:20px\">This section is advanced/optional\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.pivot()` function in Python reshapes data, essentially turning the rows into columns. Similar to `.group()`, it summarizes data, but it is a little more complicated as it changes column values in our original table into column indexes in a new table. \n",
    "\n",
    "For example, if we want to see the count of each currency in each company sector, we can use the `.pivot()` function as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions.pivot('Currency of Total Revenue', # the row index\n",
    "                'Company Sector', # the column index\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of value counts, we can also incorporate aggregations into this function just like we did with `.group()`.\n",
    "\n",
    "Now, let's look at the average `Scope 1 value` for each combination of currency and company sector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions.pivot('Currency of Total Revenue', # the row index\n",
    "                'Company Sector', # the column index\n",
    "                values = 'Scope 1 value', # the variable that is being evaluated for each combination\n",
    "                collect = np.mean # how the value is going to be aggregated\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: 2px solid #003262\">\n",
    "<hr style=\"border: 2px solid #C9B676\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00009-52f60190-e21f-4107-99a9-d42ab128df40",
    "deepnote_cell_type": "markdown",
    "tags": [
     "ignore"
    ]
   },
   "source": [
    "## 3. Visualizations\n",
    "\n",
    "In this section, we'll be able to **analyze our data visually by creating various charts and graphs.** We'll start off by looking at basic charts that we can create with the built-in visualizations with the `datascience` module. Then, we'll show off some more advanced visualizations that we can create with other visualization modules!\n",
    "\n",
    "**For Section 3.2 on advanced visualizations, don't worry too much about understanding how to write the code!** We won't ask you to re-create those types of graphs in the next notebook; instead, just focus on analyzing the graph visually to see what information you can gather from it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Basic Scatter Plots and Bar Charts with the `datascience` Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizing the `datascience` module and its built-in graphing functions, let's create some basic scatter plots and bar charts that we learned about in Notebook 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's practice creating a scatter plot in order to look at the relationship between two numeric values. For the following graph, we use `.scatter()` to view the relationship between the `Scope 1 value` and `Scope 2 value`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions.scatter('Scope 1 value', 'Scope 2 value (market-based)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the x-axis and y-axis above, we can see that the `Scope 2 value` has a much larger range of values it takes on than the `Scope 1 value`. We can also see that many of the points are concentrated in the bottom left corner, and we only have a handful of **outlier data points** that have larger Scope 1 and/or Scope 2 values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's look at some examples of bar charts. The code for these bar charts is a bit more complex, because we need to take some intermediate steps of grouping, sorting, and selecting certain columns and rows of the table in order to get a more readable graph.\n",
    "\n",
    "**If the code is a little confusing, that's okay! Just focus on being able to interpret what the graphs are telling us.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first bar chart, we group our data based on company sector and then look at the average `Scope 1 value` for every sector. From this, we can see that the `Materials` and `Energy` sectors have the highest average Scope 1 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions.group('Company Sector', np.average).barh('Company Sector', 'Scope 1 value average')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following bar chart, we want to look at the top five companies based on the average of their `Scope 1 value`. \n",
    "\n",
    "To accomplish this, we first have to group the data by the company (in case multiple students submitted data on the same company), and then sort the data in descending order of the average `Scope 1 value`. From this, we take the top 5 companies and create a bar chart from it.\n",
    "\n",
    "We've broken up this code into intermediate steps below so that it is more readable, but all of this code could have been chained together into one long line!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_company = emissions.group('Company Name', np.average)\n",
    "sorted_grouped_company = grouped_company.sort('Scope 1 value average', descending = True)\n",
    "top_five_companies = sorted_grouped_company.take([0, 1, 2, 3, 4])\n",
    "\n",
    "# In the following line, we create the bar chart: categorical column on the y-axis, numeric column on the x-axis\n",
    "top_five_companies.barh('Company Name', 'Scope 1 value average')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 More Advanced Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `datascience` module's graphing methods are quite beginner-friendly, but if we want to create more advanced, professional-looking, or informative graphs, we can use other data visualization modules, such as `Seaborn` and `Plotly`!\n",
    "\n",
    "**You won't be expected to know how to write the code to generate the following graphs for the next notebook;** we're just taking a look at them to see how we can create more complex graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we can use the `Seaborn` module (which we imported at the very beginning as `sns`) to create a graph of the counts of each company sector. From the graph below, we can see that the most common companies students picked to report data on were part of the `Apparel & Footwear` and `Energy` sectors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(y = emissions['Company Sector'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up, using the `Plotly module`, we can get really fancy with our graphs! The following graph is an interactive one -- once you run it, you'll have the option to select a type of `Currency`. This option selects only companies with that type of currency (so for the less common currency types, you'll only see a few points plotted).\n",
    "\n",
    "It then creates a scatterplot of the company's `Total Revenue` plotted against their `Scope 1 value`. It also colors the company's point based on the sector it belongs to. Select different options for the currency and see what you find!\n",
    "\n",
    "**Note:** This plot may take a few seconds to load at first and each time you select a different currency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('emissions.csv')\n",
    "\n",
    "@interact(currency = Dropdown(options = np.unique(emissions['Currency of Total Revenue']), value = 'USD'))\n",
    "def plot_px(currency):\n",
    "    mask = df['Currency of Total Revenue'].isin([currency])\n",
    "    fig = px.scatter(df[mask], x = 'Total Revenue',\n",
    "                     y = 'Scope 1 value',\n",
    "                     color = 'Company Sector',\n",
    "                     hover_data = ['Company Name'],\n",
    "                     labels= {\n",
    "                        'Scope 1 value': 'Emissions',\n",
    "                     },\n",
    "                 )\n",
    "    fig.update_layout(xaxis_title = \"Total Revenue\",\n",
    "                      yaxis_title = \"Total Direct GHG Emissions\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty cool, right? Let's see how we can utilize `Plotly` and these interactive graphs further by next focusing on one sector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 A Closer Look at the Food & Agriculture Sector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a closer look at one of the most popular sectors that your class looked at: Food & Agriculture. Below, data from 2018 through 2021 is shown for nine of the most prominent food and agricultural companies, ranging from beverage companies (Molson Coors, PepsiCo), food retailers (Tesco), and famous food companies (Nestlé). This data was gathered from a variety of sources, including various CDP reports, company sustainability reports, and the SEC (U.S. Securities and Exchange Commission) website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to load the data\n",
    "food_ag = pd.read_csv('foodag.csv')\n",
    "food_ag.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1 GHG Emissions Over Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at some trends in the total emissions of the companies over the years 2018 through 2021. Are the total emissions in the overall food & agriculture sector generally decreasing, increasing, staying flat, or fluctuating over time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = food_ag['COMPANY NAME'].unique()\n",
    "years = ['2018', '2019', '2020', '2021']\n",
    "\n",
    "@interact(x = widgets.Dropdown(options = list(companies), value = 'Danone'))\n",
    "def g(x):\n",
    "    emissions = food_ag[food_ag['COMPANY NAME'] == x][\"TOTAL EMISSIONS\"] / 1000\n",
    "    bar_container = plt.bar(years, emissions);\n",
    "    plt.ylim(0, max(emissions) + 5000)\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Total Scope 1 & Scope 2 Emissions (thousand mt CO2e)', size = 11)\n",
    "    plt.title(x + ' GHG Emissions (2018-2021)', size = 15)\n",
    "    plt.bar_label(bar_container, fmt='{:,.0f}')\n",
    "    plt.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2 Carbon Intensity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way we can make comparisons within a sector is by looking at a company's carbon intensity. **Carbon intensity is a measure of GHG emissions per unit of activity. For this data, carbon intensity is represented as the total scope 1 and scope 2 (location-based) emissions per unit of the company's revenue.**\n",
    "\n",
    "Run the code cell below to observe trends in carbon intensity for each company in the food and agriculture sector over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = food_ag['COMPANY NAME'].unique()\n",
    "years = ['2018','2019', '2020', '2021']\n",
    "\n",
    "for co in companies:\n",
    "    ci = food_ag[food_ag['COMPANY NAME'] == co][\"CARBON INTENSITY\\n(Scope 1 & 2 g CO2e / $ Sales)\"]\n",
    "    plt.plot(years, ci, label = co)\n",
    "plt.legend(loc = 'upper right', fontsize = 'xx-small')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Carbon Intensity')\n",
    "plt.title('Food & Ag Carbon Intensity Over Time (2018-2021)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at carbon intensity trends for each individual company. Run the cell below to observe different carbon intensity trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(x = widgets.Dropdown(options = list(companies), value = 'Danone'))\n",
    "def g(x):\n",
    "    ci = food_ag[food_ag['COMPANY NAME'] == x][\"CARBON INTENSITY\\n(Scope 1 & 2 g CO2e / $ Sales)\"] \n",
    "    bar_container = plt.plot(years, ci);\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Carbon Intensity (metric tons CO2e / mill total dollars)', size = 11)\n",
    "    plt.title(x + ' Carbon Intensity (2018-2021)', size = 15)\n",
    "    plt.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully this section of visualizations has shown you just how much more we can understand from our data by creating various graphs! \n",
    "\n",
    "As a reminder, in the next notebook, **you'll only be expected to re-create graphs similar to those in Section 3.1.** We may ask you some written questions about graphs similar to the ones you saw in sections 3.2 and 3.3, but you aren't expected to know how to write the code for them!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: 2px solid #003262\">\n",
    "<hr style=\"border: 2px solid #C9B676\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you've learned quite a bit, below is a summary of the topics we have covered:\n",
    "- Process of our Data Collection and Importing Modules\n",
    "    - Data Dictionary\n",
    "    - Structure of a Notebook\n",
    "- Basic Table Operations \n",
    "    - Select\n",
    "    - Sort\n",
    "    - Where (Conditioning)\n",
    "- More Advanced Table Operations\n",
    "    - Apply\n",
    "    - Group\n",
    "    - Pivot\n",
    "- Visualizations\n",
    "    - Basic data visualizations with `datascience`\n",
    "    - More advanced visualizations with `Seaborn` and `Plotly`\n",
    "    \n",
    "In the next notebook, you'll be getting some hands-on experience with many of these methods of performing data analysis!\n",
    "\n",
    "<h3>Congratulations on finishing the notebook!</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: 2px solid #003262\">\n",
    "<hr style=\"border: 2px solid #C9B676\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Final Request: Feedback Form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b> We encourage students to fill out the following feedback form to share your experience with this Modules notebook. This feedback form will take no longer than 5 minutes. At UC Berkeley Data Science Undergraduate Studies Modules, we appreciate all feedback to improve the learning of students and experience utilizing Jupyter Notebooks for Data Science Education: </b> \n",
    "</div>\n",
    "\n",
    "# [UC Berkeley Data Science Feedback Form](https://forms.gle/hPgYMxFWKXH2sVkd7)"
   ]
  }
 ],
 "metadata": {
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "693e9760-244f-475b-aa3d-f49b62665db0",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
